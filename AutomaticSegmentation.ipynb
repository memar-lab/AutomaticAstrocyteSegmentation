{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54cd5459",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T23:18:52.519789Z",
     "start_time": "2023-08-03T23:18:52.515466Z"
    }
   },
   "outputs": [],
   "source": [
    "####### Inputs #######\n",
    "model = \"UnetPlusPlus\"\n",
    "backbone = \"vgg19\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6787adbf-d287-4c7a-b78b-a356d396b898",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_list = [\"UnetPlusPlus\", \"Unet\", \"MAnet\", \"Linknet\", \"PSPNet\", \"FPN\"]\n",
    "backbone_list = [\"vgg16\", \"vgg19\", \"resnet50\", \"resnet101\", \"resnet152\", \"mobilenet_v2\", \"efficientnet-b4\"]\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from sklearn.model_selection import KFold\n",
    "import re\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "from numpy import ndarray\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import pad\n",
    "\n",
    "import random\n",
    "import csv\n",
    "\n",
    "from torchinfo import summary\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "# Takes in a .png and returns a 2D numpy array of 0's and 1's\n",
    "\n",
    "def image2nparray(image_file):\n",
    "    image = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "    image_mask = ma.make_mask(image, copy=True)\n",
    "    array_out = np.array(image_mask, dtype=int)\n",
    "    return array_out\n",
    "\n",
    "# Takes a numpy array prediction from the AI and returns png\n",
    "\n",
    "def nparray2image(nparray, filename, directory):\n",
    "    name = filename.split('.')\n",
    "    image_name = name[0] + \"_pred.png\"\n",
    "    \n",
    "    path = os.path.join(directory, image_name)\n",
    "    \n",
    "    cv2.imwrite(path, nparray*255)\n",
    "    image_out = cv2.imread(path)\n",
    "    return image_out\n",
    "\n",
    "# Concatenates and saves two images:\n",
    "    # 1. Takes prediction image and overlays it on the raw image\n",
    "    # 2. Takes manually labeled image and overlays it on the raw image\n",
    "\n",
    "def pred2comp(pred, raw, labeled, filename, directory):\n",
    "\n",
    "    # print(\"raw shape:\", raw.shape)\n",
    "    # print(\"pred shape:\", pred.shape)\n",
    "    # print(\"labeled shape:\", labeled.shape)\n",
    "\n",
    "    pred_overlay = cv2.addWeighted(raw, 0.8, pred, 0.8, 0.0)\n",
    "\n",
    "    orig_overlay = cv2.addWeighted(raw, 0.8, labeled, 0.8, 0.0)\n",
    "    \n",
    "    height = np.shape(raw)[0]\n",
    "    buffer = np.ones((height, 5, 3), dtype=np.uint8)*255\n",
    "    combined = np.hstack((raw, buffer, orig_overlay, buffer, pred_overlay)) \n",
    "\n",
    "    name = filename.split('.')\n",
    "    image_name = name[0] + \"_comp.png\"\n",
    "    path = os.path.join(directory, image_name)\n",
    "\n",
    "    cv2.imwrite(path, combined)\n",
    "\n",
    "    return combined\n",
    "\n",
    "\n",
    "# Creates the training and testing data sets for our three different methods which are 'Control', 'Random', and 'Triple'\n",
    "# Method to run is selected in the next cell \n",
    "\n",
    "class TrainingDataset(Dataset):\n",
    "    def __init__(self, raw_folder, label_folder):\n",
    "        if model_to_run == 'Triple':     \n",
    "            self.raw_images_list = os.listdir(raw_folder)\n",
    "            self.raw_images_dir = raw_folder\n",
    "            self.labeled_images = os.listdir(label_folder)\n",
    "            self.labeled_images_dir = label_folder\n",
    "\n",
    "            # Creating transform attributes\n",
    "            #self.raw_normalize = transforms.Normalize(mean = [0.0839, 0.0857, 0.0868], std = [0.1734, 0.1740, 0.1746])\n",
    "            self.jitter = transforms.ColorJitter(brightness = 0.25, contrast = 0.4)\n",
    "            self.flip = transforms.RandomHorizontalFlip(p=1.0)\n",
    "            self.to_tensor = transforms.ToTensor()\n",
    " \n",
    "        elif model_to_run == 'Random':\n",
    "            self.raw_images_list = os.listdir(raw_folder)\n",
    "            self.raw_images_dir = raw_folder\n",
    "            self.labeled_images = os.listdir(label_folder)\n",
    "            self.labeled_images_dir = label_folder\n",
    "\n",
    "            # Creating transform attributes\n",
    "            #self.raw_normalize = transforms.Normalize(mean = [0.0839, 0.0857, 0.0868], std = [0.1734, 0.1740, 0.1746])\n",
    "            self.jitter = transforms.ColorJitter(brightness = 0.25, contrast = 0.4)\n",
    "            self.flip = transforms.RandomHorizontalFlip(p=1.0)\n",
    "            self.combined = transforms.Compose([\n",
    "                transforms.ColorJitter(brightness = 0.25, contrast = 0.4),\n",
    "                transforms.RandomHorizontalFlip(p=1.0)])\n",
    "            self.to_tensor = transforms.ToTensor()\n",
    "        \n",
    "        elif model_to_run == 'Control':\n",
    "            self.raw_images_list = os.listdir(raw_folder)\n",
    "            self.raw_images_dir = raw_folder\n",
    "            self.labeled_images = os.listdir(label_folder)\n",
    "            self.labeled_images_dir = label_folder\n",
    "\n",
    "            # Creating transform attributes\n",
    "            #self.raw_normalize = transforms.Normalize(mean = [0.0839, 0.0857, 0.0868], std = [0.1734, 0.1740, 0.1746])\n",
    "            # (mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225]) this is the original\n",
    "            # Corrected means and standard deviations are: mean=[0.0839, 0.0857, 0.0868], std=[0.1734, 0.1740, 0.1746]\n",
    "            self.to_tensor = transforms.ToTensor()\n",
    "            \n",
    "    def __len__(self):\n",
    "        # size (length) of the dataset\n",
    "        if model_to_run == 'Triple':\n",
    "            return (len(self.raw_images_list)) *3\n",
    "        else:\n",
    "            return len(self.raw_images_list)\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if model_to_run == 'Triple': \n",
    "            # Select the \"index\"th item from the dataset\n",
    "            # Will return the item in the row \"index\" in self.details\n",
    "            true_length = len(self.raw_images_list)\n",
    "            category = index // true_length\n",
    "            item_data = {}\n",
    "\n",
    "            if category == 0:\n",
    "                # proceed as normal, so original image\n",
    "                orig_filename = self.raw_images_list[index]\n",
    "                item_data['filename'] = orig_filename\n",
    "                item_data['categoryname'] = orig_filename\n",
    "            \n",
    "                raw_image = os.path.join(self.raw_images_dir, orig_filename)\n",
    "                raw_image_data = cv2.imread(raw_image)\n",
    "                raw_image_data = self.to_tensor(raw_image_data)\n",
    "                item_data['rawimg'] = raw_image_data\n",
    "                item_data['raw'] = raw_image_data\n",
    "                # item_data['raw'] = self.raw_normalize(raw_image_data)\n",
    "\n",
    "                label_dir = os.path.join(self.labeled_images_dir, orig_filename)\n",
    "                label_image_data = cv2.imread(label_dir)\n",
    "                label_image_data = self.to_tensor(label_image_data)\n",
    "                item_data['labelimg'] = label_image_data\n",
    "                item_data['labeled'] = image2nparray(label_dir)\n",
    "\n",
    "            elif category == 1:\n",
    "                # Apply color jitter\n",
    "                index = index % true_length\n",
    "\n",
    "                orig_filename = self.raw_images_list[index]\n",
    "                item_data['filename'] = orig_filename\n",
    "                start_name = orig_filename.split('.')\n",
    "                new_name = start_name[0] + \"_coljit.png\"\n",
    "                item_data['categoryname'] = new_name\n",
    "        \n",
    "                raw_image = os.path.join(self.raw_images_dir, orig_filename)\n",
    "                raw_image_data = cv2.imread(raw_image)\n",
    "                raw_image_data = self.to_tensor(raw_image_data)\n",
    "                raw_image_data = self.jitter(raw_image_data)\n",
    "                item_data['rawimg'] = raw_image_data\n",
    "                item_data['raw'] = raw_image_data\n",
    "                # item_data['raw'] = self.raw_normalize(raw_image_data)\n",
    "\n",
    "                label_dir = os.path.join(self.labeled_images_dir, orig_filename)\n",
    "                label_image_data = cv2.imread(label_dir)\n",
    "                label_image_data = self.to_tensor(label_image_data)\n",
    "                item_data['labelimg'] = label_image_data\n",
    "                item_data['labeled'] = image2nparray(label_dir)\n",
    "\n",
    "            else:\n",
    "                # RandomHorizontalFlip\n",
    "                index = index % true_length\n",
    "\n",
    "                orig_filename = self.raw_images_list[index]\n",
    "                item_data['filename'] = orig_filename\n",
    "                start_name = orig_filename.split('.')\n",
    "                new_name = start_name[0] + \"_hflip.png\"\n",
    "                item_data['categoryname'] = new_name\n",
    "            \n",
    "                raw_image = os.path.join(self.raw_images_dir, orig_filename)\n",
    "                raw_image_data = cv2.imread(raw_image)\n",
    "                raw_image_data = self.to_tensor(raw_image_data)\n",
    "                raw_image_data = self.flip(raw_image_data)\n",
    "                item_data['rawimg'] = raw_image_data\n",
    "                item_data['raw'] = raw_image_data\n",
    "                # item_data['raw'] = self.raw_normalize(raw_image_data)\n",
    "\n",
    "                label_dir = os.path.join(self.labeled_images_dir, orig_filename)\n",
    "                label_image_data = cv2.imread(label_dir)\n",
    "                label_image_data = self.to_tensor(label_image_data)\n",
    "                label_image_mask = image2nparray(label_dir)\n",
    "                label_image_mask = self.to_tensor(label_image_mask)\n",
    "                label_image_data = self.flip(label_image_data)\n",
    "                label_image_mask = self.flip(label_image_mask)\n",
    "                item_data['labelimg'] = label_image_data\n",
    "                item_data['labeled'] = torch.squeeze(label_image_mask)\n",
    "\n",
    "                # For Debugging\n",
    "                # assert item_data['labeled'].shape == item_data['raw'][:, :, 0].shape, \"The label width and height does not match the raw image\"\n",
    "        \n",
    "        elif model_to_run == 'Random': \n",
    "            # Select the \"index\"th item from the dataset\n",
    "            # Will return the item in the row \"index\" in self.details\n",
    "            random_number = random.random()\n",
    "\n",
    "            item_data = {}\n",
    "            orig_filename = self.raw_images_list[index]\n",
    "            item_data['filename'] = orig_filename\n",
    "        \n",
    "            raw_image = os.path.join(self.raw_images_dir, orig_filename)\n",
    "            raw_image_data = cv2.imread(raw_image)\n",
    "            raw_image_data = self.to_tensor(raw_image_data)\n",
    "\n",
    "            label_dir = os.path.join(self.labeled_images_dir, orig_filename)\n",
    "            label_image_data = cv2.imread(label_dir)\n",
    "            label_image_data = self.to_tensor(label_image_data)\n",
    "            label_image_mask = image2nparray(label_dir)\n",
    "\n",
    "            # If statement to randomly apply transforms\n",
    "            if random_number < 0.25:\n",
    "                # Original/ no transforms\n",
    "                item_data['categoryname'] = orig_filename\n",
    "                item_data['rawimg'] = raw_image_data\n",
    "                item_data['raw'] = raw_image_data\n",
    "                # item_data['raw'] = self.raw_normalize(raw_image_data)\n",
    "                item_data['labelimg'] = label_image_data\n",
    "                item_data['labeled'] = label_image_mask\n",
    "            elif random_number < 0.50:\n",
    "                # ColorJitter only\n",
    "                start_name = orig_filename.split('.')\n",
    "                new_name = start_name[0] + \"_coljit.png\"\n",
    "                item_data['categoryname'] = new_name\n",
    "                raw_image_data = self.jitter(raw_image_data)\n",
    "                item_data['rawimg'] = raw_image_data\n",
    "                item_data['raw'] = raw_image_data\n",
    "                # item_data['raw'] = self.raw_normalize(raw_image_data)\n",
    "                item_data['labelimg'] = label_image_data\n",
    "                item_data['labeled'] = label_image_mask\n",
    "            elif random_number < 0.75:\n",
    "                # HorizontalFlip only\n",
    "                start_name = orig_filename.split('.')\n",
    "                new_name = start_name[0] + \"_hflip.png\"\n",
    "                item_data['categoryname'] = new_name\n",
    "                raw_image_data = self.flip(raw_image_data)\n",
    "                item_data['rawimg'] = raw_image_data\n",
    "                item_data['raw'] = raw_image_data\n",
    "                # item_data['raw'] = self.raw_normalize(raw_image_data)\n",
    "                label_image_mask = self.to_tensor(label_image_mask)\n",
    "                label_image_data = self.flip(label_image_data)\n",
    "                label_image_mask = self.flip(label_image_mask)\n",
    "                item_data['labelimg'] = label_image_data\n",
    "                item_data['labeled'] = torch.squeeze(label_image_mask)\n",
    "            else:\n",
    "                # Both\n",
    "                start_name = orig_filename.split('.')\n",
    "                new_name = start_name[0] + \"_both.png\"\n",
    "                item_data['categoryname'] = new_name\n",
    "                raw_image_data = self.combined(raw_image_data)\n",
    "                item_data['rawimg'] = raw_image_data\n",
    "                item_data['raw'] = raw_image_data\n",
    "                # item_data['raw'] = self.raw_normalize(raw_image_data)\n",
    "                label_image_mask = self.to_tensor(label_image_mask)\n",
    "                label_image_data = self.flip(label_image_data)\n",
    "                label_image_mask = self.flip(label_image_mask)\n",
    "                item_data['labelimg'] = label_image_data\n",
    "                item_data['labeled'] = torch.squeeze(label_image_mask)\n",
    "        elif model_to_run == 'Control':\n",
    "            # Select the \"index\"th item from the dataset\n",
    "            # Will return the item in the row \"index\" in self.details\n",
    "\n",
    "            item_data = {}\n",
    "            orig_filename = self.raw_images_list[index]\n",
    "            item_data['filename'] = orig_filename\n",
    "        \n",
    "            raw_image = os.path.join(self.raw_images_dir, orig_filename)\n",
    "            raw_image_data = cv2.imread(raw_image)\n",
    "            raw_image_data = self.to_tensor(raw_image_data)     \n",
    "            item_data['rawimg'] = raw_image_data\n",
    "            item_data['raw'] = raw_image_data\n",
    "            # item_data['raw'] = self.raw_normalize(raw_image_data)  \n",
    "\n",
    "            label_dir = os.path.join(self.labeled_images_dir, orig_filename)\n",
    "            label_image_data = cv2.imread(label_dir)\n",
    "            item_data['labelimg'] = self.to_tensor(label_image_data)\n",
    "            item_data['labeled'] = image2nparray(label_dir)\n",
    "        \n",
    "            # For Debugging\n",
    "            # assert item_data['labeled'].shape == item_data['raw'][:, :, 0].shape, \"The label width and height does not match the raw image\"\n",
    "        \n",
    "        # print(\"Shape of labeled:\", item_data['labeled'].shape)\n",
    "        # print(\"Shape of labelimg:\", item_data['labelimg'].shape)\n",
    "        # print(\"Shape of raw:\", item_data['raw'].shape)\n",
    "        # print(\"Shape of rawimg:\", item_data['rawimg'].shape)\n",
    "        \n",
    "\n",
    "\n",
    "            # Get current sizes\n",
    "            h, w = item_data['labeled'].shape  # labeled is still 2D at this point\n",
    "\n",
    "            # Compute required padding\n",
    "            pad_h = (32 - (h % 32)) % 32\n",
    "            pad_w = (32 - (w % 32)) % 32\n",
    "\n",
    "            # Split padding between top/bottom and left/right\n",
    "            pad_top = pad_h // 2\n",
    "            pad_bottom = pad_h - pad_top\n",
    "            pad_left = pad_w // 2\n",
    "            pad_right = pad_w - pad_left\n",
    "\n",
    "            # Save padding info for later uncropping\n",
    "            item_data['pad'] = {\n",
    "                'top': pad_top,\n",
    "                'bottom': pad_bottom,\n",
    "                'left': pad_left,\n",
    "                'right': pad_right,\n",
    "                'orig_hw': (h, w)  # optional but handy for sanity checks\n",
    "            }\n",
    "            # Apply padding to label (NumPy)\n",
    "            item_data['labeled'] = np.pad(item_data['labeled'],\n",
    "                                        ((pad_top, pad_bottom), (pad_left, pad_right)),\n",
    "                                        mode='constant')\n",
    "            item_data['labeled'] = np.expand_dims(item_data['labeled'], axis=0)\n",
    "\n",
    "            # Apply padding to raw (Torch tensor, using F.pad)\n",
    "            item_data['raw'] = pad(item_data['raw'],\n",
    "                                (pad_left, pad_top, pad_right, pad_bottom),\n",
    "                                padding_mode='constant')\n",
    "            \n",
    "\n",
    "        \n",
    "        return item_data\n",
    "    \n",
    "def reset_all_weights(model: nn.Module) -> None:\n",
    "    \"\"\"\n",
    "    refs:\n",
    "        - https://discuss.pytorch.org/t/how-to-re-set-alll-parameters-in-a-network/20819/6\n",
    "        - https://stackoverflow.com/questions/63627997/reset-parameters-of-a-neural-network-in-pytorch\n",
    "        - https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
    "    \"\"\"\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def weight_reset(m: nn.Module):\n",
    "        # - check if the current module has reset_parameters & if it's callabed called it on m\n",
    "        reset_parameters = getattr(m, \"reset_parameters\", None)\n",
    "        if callable(reset_parameters):\n",
    "            m.reset_parameters()\n",
    "\n",
    "    # Applies fn recursively to every submodule see: https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
    "    model.apply(fn=weight_reset)\n",
    "\n",
    "\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(model_path, device):\n",
    "    model = torch.load(model_path, map_location=device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image_path, device):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    preprocess = transforms.ToTensor()\n",
    "    image = preprocess(image)\n",
    "\n",
    "    _, H, W = image.shape\n",
    "\n",
    "    # --- compute minimal padding to make H,W divisible by 32 ---\n",
    "    pad_h = (32 - (H % 32)) % 32\n",
    "    pad_w = (32 - (W % 32)) % 32\n",
    "\n",
    "    pad_top    = pad_h // 2\n",
    "    pad_bottom = pad_h - pad_top\n",
    "    pad_left   = pad_w // 2\n",
    "    pad_right  = pad_w - pad_left\n",
    "\n",
    "    pad_info = {\n",
    "        \"top\": int(pad_top),\n",
    "        \"bottom\": int(pad_bottom),\n",
    "        \"left\": int(pad_left),\n",
    "        \"right\": int(pad_right),\n",
    "        \"orig_hw\": (int(H), int(W))\n",
    "    }\n",
    "\n",
    "    # --- apply padding only if needed; F.pad order: (left, right, top, bottom) ---\n",
    "    if pad_h or pad_w:\n",
    "        image = F.pad(image, (pad_left, pad_right, pad_top, pad_bottom), mode='constant', value=0)\n",
    "\n",
    "    # add batch dimension and move to device\n",
    "    image = image.unsqueeze(0).to(device)  # (1,C,H',W')\n",
    "    \n",
    "    return image.to(device), pad_info\n",
    "\n",
    "# Function to postprocess the output and save the segmentation result\n",
    "def postprocess_and_save(output, save_path, pad_info=None):\n",
    "    pred = output.sigmoid().cpu().numpy().squeeze()\n",
    "    pred = (pred > 0.5).astype(np.uint8)  # Convert to binary mask\n",
    "    # --- crop using dynamic padding info (if provided) ---\n",
    "    if pad_info is not None:\n",
    "        pt = int(pad_info.get('top', 0))\n",
    "        pb = int(pad_info.get('bottom', 0))\n",
    "        pl = int(pad_info.get('left', 0))\n",
    "        pr = int(pad_info.get('right', 0))\n",
    "\n",
    "        h, w = pred.shape\n",
    "        h_end = h - pb if pb > 0 else h\n",
    "        w_end = w - pr if pr > 0 else w\n",
    "        pred = pred[pt:h_end, pl:w_end]\n",
    "\n",
    "    pred_image = Image.fromarray(pred * 255)  # Convert to image\n",
    "    pred_image.save(save_path)\n",
    "\n",
    "# Main function to segment images\n",
    "def segment_images(model_path, input_folder, output_folder, device):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    model = load_model(model_path, device)\n",
    "    \n",
    "    image_files = [f for f in os.listdir(input_folder) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    total_images = len(image_files)\n",
    "    print(f\"Total test images: {total_images}\")\n",
    "\n",
    "    for image_name in image_files:\n",
    "        image_path = os.path.join(input_folder, image_name)\n",
    "        save_path = os.path.join(output_folder, image_name)\n",
    "        image, pad_info = preprocess_image(image_path, device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(image)\n",
    "            postprocess_and_save(output, save_path, pad_info)\n",
    "    \n",
    "    print(\"Segmentation finished\")\n",
    "\n",
    "\n",
    "model_classes = {\n",
    "    \"FPN\": smp.FPN,\n",
    "    \"Unet\": smp.Unet,\n",
    "    \"MAnet\": smp.MAnet,\n",
    "    \"Linknet\": smp.Linknet,\n",
    "    \"PSPNet\": smp.PSPNet,\n",
    "    \"UnetPlusPlus\": smp.UnetPlusPlus\n",
    "}\n",
    "\n",
    "NNModel = model_classes[model] # The class of model we are using\n",
    "nn_name = NNModel.__name__ # gets the name of the nn class as a str\n",
    "backbone = backbone # Encoder model to serve as the backbone of our ml model\n",
    "print(\"Training\", nn_name, \"with backbone\", backbone)\n",
    "model_to_run = 'Control'\n",
    "base_model_path = \"Models/\" + nn_name.lower() + \"_\" + backbone  + \"/\"\n",
    "model_path = base_model_path + \"net.pth\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "### Find all the subfolders\n",
    "# Define the main path\n",
    "main_path = \"PredictionDataset/\"\n",
    "\n",
    "\n",
    "# List to store paths of 'Raw' folders\n",
    "raw_folders = []\n",
    "\n",
    "# Walk through the directory tree\n",
    "for root, dirs, files in os.walk(main_path):\n",
    "    # Check if the current directory name is \"Raw\"\n",
    "    if os.path.basename(root) == \"Raw\":\n",
    "        raw_folders.append(root)\n",
    "\n",
    "\n",
    "# List of addresses for prediction paths\n",
    "pred_paths = [os.path.join(os.path.dirname(folder), \"Segmentation/\") for folder in raw_folders]\n",
    "\n",
    "# Loop over the lists\n",
    "for i in range(0, len(raw_folders)):\n",
    "    input_folder = raw_folders[i]\n",
    "    output_folder = pred_paths[i]\n",
    "\n",
    "    # Ensure the prediction path exists or create it if necessary\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    segment_images(model_path, input_folder, output_folder, device)\n",
    "    print(f\"Processing folder {i + 1} of {len(raw_folders)}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "34718bd5e5ff0ec954d04da905bd4ff4d511a0bfb6f9a1aa7037f750dbb407a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
